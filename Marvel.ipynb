{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Marvel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq5oWT6lfQhg"
      },
      "source": [
        "#### Ejecutar en caso de tener el dataset subido a Google Colaboratory para entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq9ZEXsYaEa2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNQdczcL03eq"
      },
      "source": [
        "#### Librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96Lv18r06IX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa2fEbdiMRDk"
      },
      "source": [
        "#### Funciones útiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4osNuN_fOio"
      },
      "source": [
        "def print_info(  test_gen, preds, print_code, save_dir, subject ):\n",
        "    class_dict=test_gen.class_indices\n",
        "    labels= test_gen.labels\n",
        "    file_names= test_gen.filenames \n",
        "    error_list=[]\n",
        "    true_class=[]\n",
        "    pred_class=[]\n",
        "    prob_list=[]\n",
        "    new_dict={}\n",
        "    error_indices=[]\n",
        "    y_pred=[]\n",
        "    for key,value in class_dict.items():\n",
        "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
        "    # store new_dict as a text fine in the save_dir\n",
        "    classes=list(new_dict.values())     # list of string of class names\n",
        "    dict_as_text=str(new_dict)\n",
        "    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n",
        "    dict_path=os.path.join(save_dir,dict_name)    \n",
        "    with open(dict_path, 'w') as x_file:\n",
        "        x_file.write(dict_as_text)    \n",
        "    errors=0      \n",
        "    for i, p in enumerate(preds):\n",
        "        pred_index=np.argmax(p)        \n",
        "        true_index=labels[i]  # labels are integer values\n",
        "        if pred_index != true_index: # a misclassification has occurred\n",
        "            error_list.append(file_names[i])\n",
        "            true_class.append(new_dict[true_index])\n",
        "            pred_class.append(new_dict[pred_index])\n",
        "            prob_list.append(p[pred_index])\n",
        "            error_indices.append(true_index)            \n",
        "            errors=errors + 1\n",
        "        y_pred.append(pred_index)    \n",
        "    if print_code !=0:\n",
        "        if errors>0:\n",
        "            if print_code>errors:\n",
        "                r=errors\n",
        "            else:\n",
        "                r=print_code           \n",
        "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
        "            print(msg)\n",
        "            for i in range(r):\n",
        "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(error_list[i], pred_class[i],true_class[i], ' ', prob_list[i])\n",
        "                print(msg)\n",
        "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
        "        else:\n",
        "            msg='With accuracy of 100 % there are no errors to print'\n",
        "            print(msg)\n",
        "    if errors>0:\n",
        "        plot_bar=[]\n",
        "        plot_class=[]\n",
        "        for  key, value in new_dict.items():        \n",
        "            count=error_indices.count(key) \n",
        "            if count!=0:\n",
        "                plot_bar.append(count) # list containg how many times a class c had an error\n",
        "                plot_class.append(value)   # stores the class \n",
        "        fig=plt.figure()\n",
        "        fig.set_figheight(len(plot_class)/3)\n",
        "        fig.set_figwidth(10)\n",
        "        plt.style.use('fivethirtyeight')\n",
        "        for i in range(0, len(plot_class)):\n",
        "            c=plot_class[i]\n",
        "            x=plot_bar[i]\n",
        "            plt.barh(c, x, )\n",
        "            plt.title( ' Errors by Class on Test Set') \n",
        "    y_true= np.array(labels)        \n",
        "    y_pred=np.array(y_pred)\n",
        "    if len(classes)<= 30:\n",
        "        cm = confusion_matrix(y_true, y_pred )        \n",
        "        length=len(classes)\n",
        "        if length<8:\n",
        "            fig_width=8\n",
        "            fig_height=8\n",
        "        else:\n",
        "            fig_width=length\n",
        "            fig_height=length\n",
        "        plt.figure(figsize=(fig_width, fig_height))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "        plt.xticks(np.arange(length)+.5, classes, rotation=90)\n",
        "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()    \n",
        "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTjCv3T3fOis"
      },
      "source": [
        "def tr_plot(tr_data, start_epoch):\n",
        "    \n",
        "    #Plot the training and validation data\n",
        "    tacc=tr_data.history['accuracy']\n",
        "    tloss=tr_data.history['loss']\n",
        "    vacc=tr_data.history['val_accuracy']\n",
        "    vloss=tr_data.history['val_loss']\n",
        "    Epoch_count=len(tacc)+ start_epoch\n",
        "    Epochs=[]\n",
        "    for i in range (start_epoch ,Epoch_count):\n",
        "        Epochs.append(i+1)   \n",
        "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
        "    val_lowest=vloss[index_loss]\n",
        "    index_acc=np.argmax(vacc)\n",
        "    acc_highest=vacc[index_acc]\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
        "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
        "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
        "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
        "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
        "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
        "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
        "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "    plt.tight_layout\n",
        "    #plt.style.use('fivethirtyeight')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHOkCevufOiu"
      },
      "source": [
        "def display_eval_metrics(e_data):\n",
        "    msg='Model Metrics after Training'\n",
        "    print(msg)\n",
        "    msg='{0:^24s}{1:^24s}'.format('Metric', 'Value')\n",
        "    print(msg)\n",
        "    for key,value in e_data.items():\n",
        "        print (f'{key:^24s}{value:^24.5f}')\n",
        "    acc=e_data['accuracy']* 100\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWN93QLdfOiw"
      },
      "source": [
        "def scalar(img):\n",
        "        return img/127.5 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOlXmc2w0_EN"
      },
      "source": [
        "#### Rutas a los diretorios con las imagenes. Cambiar la variable path por la ruta donde se encuentre el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9g5RICB1DrL"
      },
      "source": [
        "#Path to images\n",
        "path = \"/content/drive/MyDrive/marvel/to/my/images\"\n",
        "image_dir = Path(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBkbiEQF1Gv3"
      },
      "source": [
        "#### Preprocesamiento de las imagenes con generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hxsUFgb1J7A"
      },
      "source": [
        "labels = []    \n",
        "filepaths = list(image_dir.glob('**/*.jpg'))\n",
        "for f in filepaths:\n",
        "\ttsplit = os.path.split(os.path.split(f)[0])[1] # split filenames to get the label\n",
        "\tlabels.append(tsplit)    \n",
        "filepaths = pd.Series(filepaths, name = 'Filepath').astype(str)\n",
        "labels = pd.Series(labels, name = 'Label')\n",
        "image_df = pd.concat([filepaths, labels], axis = 1) # concatenate series into a data frame\n",
        "\n",
        "#Train and test split ratio\n",
        "train_split = 0.9\n",
        "test_split = 0.05\n",
        "\n",
        "# split dataframe into train, test and valid dataframes    \n",
        "dummy_split = test_split/(1.0 - train_split)\n",
        "train_df, no_train_df = train_test_split(image_df, train_size = train_split, shuffle = True, random_state = 123)\n",
        "test_df, valid_df = train_test_split(no_train_df, train_size = dummy_split, shuffle = True, random_state = 123)\n",
        "\n",
        "#Generator of images\n",
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function = scalar)\n",
        "\n",
        "#Train images generator\n",
        "train_gen = generator.flow_from_dataframe(train_df, x_col = 'Filepath', y_col = 'Label', target_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\tclass_mode = 'categorical', batch_size = 80, shuffle = True, random_state = 123)\n",
        "#Test images generator\t\t\t\t\t\t\t\t\n",
        "test_gen = generator.flow_from_dataframe(test_df, x_col = 'Filepath', y_col = 'Label', target_size = (224, 224), \n",
        "\t\t\t\t\t\t\t\tclass_mode = 'categorical', batch_size = 32, shuffle = False)\n",
        "#Validation images generator\n",
        "valid_gen = generator.flow_from_dataframe(valid_df, x_col = 'Filepath', y_col = 'Label', target_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\tclass_mode = 'categorical', batch_size = 32, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBaeVj9H1lLG"
      },
      "source": [
        "#### Modelo MobileNet usando transfer - learning. Se puede usar cualquier otro [modelo pre entrenado de Keras](https://keras.io/api/applications/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNHXb9371yKh"
      },
      "source": [
        "#MobileNet\n",
        "pretrained_model = tf.keras.applications.MobileNet(\n",
        "    input_shape = (224, 224, 3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling = 'max',\n",
        ")\n",
        "\n",
        "#Freeze all layers \n",
        "pretrained_model.trainable = False \n",
        "\n",
        "#Inputs are the model inputs\n",
        "inputs = pretrained_model.input\n",
        "\n",
        "#We define our own top classifier with 0.4 rate dropout and eight neurons softmax function\n",
        "x = pretrained_model.output\n",
        "x = tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001 )(x)\n",
        "x = tf.keras.layers.Dense(1024, kernel_regularizer = tf.keras.regularizers.l2(l = 0.016), activity_regularizer = tf.keras.regularizers.l1(0.006),\n",
        "        bias_regularizer = tf.keras.regularizers.l1(0.006), activation='relu', kernel_initializer = tf.keras.initializers.GlorotUniform(seed = 123))(x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.3, seed = 123)(x) \n",
        "output = tf.keras.layers.Dense(8, activation = 'softmax', kernel_initializer = tf.keras.initializers.GlorotUniform(seed = 123))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "#Compile model with lr = 0.001 and categorical loss entropy\n",
        "model.compile(Adamax(lr = 0.001), loss = 'categorical_crossentropy', metrics = 'accuracy') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzWq1tnKlcPY"
      },
      "source": [
        "#### Imprimimos la arquitectura del modelo cargado con el clasificador propio para comprobar que está correcta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vamtJyx8lXkO"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wku8S7-OBLzq"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrFQ-X8gBNd6"
      },
      "source": [
        "history = model.fit(x = train_gen,  epochs = 10, verbose = 1, callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor = 'val_loss',\n",
        "            patience = 3,\n",
        "            restore_best_weights = True\n",
        "        )\n",
        "    ],  validation_data = valid_gen,\n",
        "                 shuffle = False,  initial_epoch = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IydzOa5SfOi3"
      },
      "source": [
        "#### Plotear los resultados de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Jv3J75fTDa"
      },
      "source": [
        "tr_plot(history, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuNBEYUIfOi3"
      },
      "source": [
        "#### Salvar el modelo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8SeG1z-CSXp"
      },
      "source": [
        "path_to_save = \"path/to/save/my/model\"\n",
        "model.save(path_to_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgnJjGvsfOi4"
      },
      "source": [
        "#### Imprimir matriz de confusión y classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEI1P0pZfOi4"
      },
      "source": [
        "preds=model.predict(test_gen,  verbose=1)\n",
        "print_code=25 # maximum number of misclassifications to print out\n",
        "save_dir = r'./'\n",
        "subject = 'marvel characters'\n",
        "print_info(  test_gen, preds, print_code, save_dir, subject )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}